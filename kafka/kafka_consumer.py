import json
import pickle
import time
import numpy as np
from kafka import KafkaConsumer
import mysql.connector
from mysql.connector import Error
import logging
from typing import Dict, Any

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class HappinessKafkaConsumer:
    """
    Consumidor de Kafka para predicci√≥n de Happiness Score en tiempo real.
    Consume mensajes, realiza predicciones y almacena en MySQL.
    """
    
    def __init__(self,
                 bootstrap_servers: str = 'localhost:9092',
                 topic: str = 'happiness-data',
                 group_id: str = 'happiness-prediction-group',
                 model_path: str = 'modelo_regresion_lineal.pkl',
                 mysql_config: Dict[str, Any] = None):
        """
        Inicializa el consumidor de Kafka.
        
        Args:
            bootstrap_servers: Direcci√≥n del servidor Kafka
            topic: Nombre del topic de Kafka
            group_id: ID del grupo de consumidores
            model_path: Ruta al modelo .pkl guardado
            mysql_config: Configuraci√≥n de conexi√≥n MySQL
        """
        self.topic = topic
        self.model = None
        self.mysql_config = mysql_config or self._default_mysql_config()
        
        # Cargar modelo
        self._load_model(model_path)
        
        # Configurar consumidor de Kafka
        try:
            self.consumer = KafkaConsumer(
                topic,
                bootstrap_servers=bootstrap_servers,
                group_id=group_id,
                value_deserializer=lambda m: json.loads(m.decode('utf-8')),
                key_deserializer=lambda k: k.decode('utf-8') if k else None,
                auto_offset_reset='earliest',  # Leer desde el inicio
                enable_auto_commit=True,
                auto_commit_interval_ms=1000,
                max_poll_records=10
            )
            logger.info(f"‚úÖ Consumidor Kafka inicializado: {bootstrap_servers}")
            logger.info(f"üì• Suscrito al topic: {topic}")
        except Exception as e:
            logger.error(f"‚ùå Error al inicializar consumidor Kafka: {e}")
            raise
        
        # Configurar conexi√≥n MySQL
        self._setup_mysql_connection()
        self._create_predictions_table()
    
    def _default_mysql_config(self) -> Dict[str, Any]:
        """Retorna configuraci√≥n por defecto de MySQL"""
        return {
            'host': 'localhost',
            'port': 3306,
            'database': 'happiness_db',
            'user': 'root',
            'password': 'root'
        }
    
    def _load_model(self, model_path: str) -> None:
        """
        Carga el modelo de ML desde archivo .pkl
        
        Args:
            model_path: Ruta al archivo del modelo
        """
        try:
            with open(model_path, 'rb') as f:
                self.model = pickle.load(f)
            logger.info(f"‚úÖ Modelo cargado desde {model_path}")
        except FileNotFoundError:
            logger.error(f"‚ùå Archivo de modelo no encontrado: {model_path}")
            logger.info("üí° Guardando modelo actual...")
            self._save_current_model(model_path)
        except Exception as e:
            logger.error(f"‚ùå Error al cargar modelo: {e}")
            raise
    
    def _save_current_model(self, model_path: str) -> None:
        """Guarda el modelo actual (placeholder para generar .pkl si no existe)"""
        logger.warning("‚ö†Ô∏è Por favor, guarda tu modelo entrenado como .pkl")
        logger.info("üí° Ejemplo: pickle.dump(modelo_lr, open('modelo_regresion_lineal.pkl', 'wb'))")
    
    def _setup_mysql_connection(self) -> None:
        """Configura la conexi√≥n a MySQL y crea la base de datos si no existe"""
        try:
            # Primero conectar sin especificar base de datos para crearla
            config_without_db = self.mysql_config.copy()
            database_name = config_without_db.pop('database')
            
            # Conectar a MySQL sin BD
            temp_conn = mysql.connector.connect(**config_without_db)
            cursor = temp_conn.cursor()
            
            # Crear base de datos si no existe
            cursor.execute(f"CREATE DATABASE IF NOT EXISTS {database_name}")
            logger.info(f"‚úÖ Base de datos '{database_name}' verificada/creada")
            
            cursor.close()
            temp_conn.close()
            
            # Ahora conectar a la base de datos espec√≠fica
            self.mysql_conn = mysql.connector.connect(**self.mysql_config)
            if self.mysql_conn.is_connected():
                logger.info(f"‚úÖ Conectado a MySQL: {self.mysql_config['database']}")
        except Error as e:
            logger.error(f"‚ùå Error al conectar a MySQL: {e}")
            logger.info("üí° Aseg√∫rate de que MySQL est√° corriendo y las credenciales son correctas")
            raise
    
    def _create_predictions_table(self) -> None:
        """Crea la tabla de predicciones si no existe"""
        create_table_query = """
        CREATE TABLE IF NOT EXISTS predictions (
            id INT AUTO_INCREMENT PRIMARY KEY,
            record_id INT NOT NULL,
            timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            country VARCHAR(100),
            year INT,
            
            -- Caracter√≠sticas (Features)
            gdp_per_capita FLOAT,
            social_support FLOAT,
            healthy_life_expectancy FLOAT,
            freedom_to_make_life_choices FLOAT,
            generosity FLOAT,
            perceptions_of_corruption FLOAT,
            
            -- Scores
            actual_score FLOAT,
            predicted_score FLOAT,
            prediction_error FLOAT,
            
            -- Metadata
            processing_time_ms FLOAT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            
            INDEX idx_country (country),
            INDEX idx_year (year),
            INDEX idx_timestamp (timestamp)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """
        
        try:
            cursor = self.mysql_conn.cursor()
            cursor.execute(create_table_query)
            self.mysql_conn.commit()
            cursor.close()
            logger.info("‚úÖ Tabla 'predictions' verificada/creada")
        except Error as e:
            logger.error(f"‚ùå Error al crear tabla: {e}")
            raise
    
    def extract_features(self, record: Dict[str, Any]) -> np.ndarray:
        """
        Extrae las caracter√≠sticas del registro para predicci√≥n.
        
        Args:
            record: Registro del mensaje de Kafka
            
        Returns:
            Array de numpy con las caracter√≠sticas ordenadas
        """
        features = record['features']
        
        # Orden debe coincidir con el orden de entrenamiento del modelo
        feature_vector = np.array([
            features['GDP_per_capita'],
            features['Social_support'],
            features['Healthy_life_expectancy'],
            features['Freedom_to_make_life_choices'],
            features['Generosity'],
            features['Perceptions_of_corruption']
        ]).reshape(1, -1)
        
        return feature_vector
    
    def predict(self, features: np.ndarray) -> float:
        """
        Realiza predicci√≥n usando el modelo cargado.
        
        Args:
            features: Array de caracter√≠sticas
            
        Returns:
            Score predicho
        """
        try:
            prediction = self.model.predict(features)[0]
            return float(prediction)
        except Exception as e:
            logger.error(f"‚ùå Error en predicci√≥n: {e}")
            return 0.0
    
    def save_to_mysql(self, record: Dict[str, Any], 
                      predicted_score: float,
                      processing_time: float) -> None:
        """
        Guarda el registro y la predicci√≥n en MySQL.
        
        Args:
            record: Registro original
            predicted_score: Score predicho
            processing_time: Tiempo de procesamiento en ms
        """
        insert_query = """
        INSERT INTO predictions (
            record_id, country, year,
            gdp_per_capita, social_support, healthy_life_expectancy,
            freedom_to_make_life_choices, generosity, perceptions_of_corruption,
            actual_score, predicted_score, prediction_error, processing_time_ms
        ) VALUES (
            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
        )
        """
        
        features = record['features']
        actual_score = record['actual_score']
        prediction_error = abs(actual_score - predicted_score)
        
        values = (
            record['record_id'],
            record['country'],
            record['year'],
            features['GDP_per_capita'],
            features['Social_support'],
            features['Healthy_life_expectancy'],
            features['Freedom_to_make_life_choices'],
            features['Generosity'],
            features['Perceptions_of_corruption'],
            actual_score,
            predicted_score,
            prediction_error,
            processing_time
        )
        
        try:
            cursor = self.mysql_conn.cursor()
            cursor.execute(insert_query, values)
            self.mysql_conn.commit()
            cursor.close()
            logger.debug(f"üíæ Registro {record['record_id']} guardado en MySQL")
        except Error as e:
            logger.error(f"‚ùå Error al guardar en MySQL: {e}")
            self.mysql_conn.rollback()
    
    def process_message(self, message) -> None:
        """
        Procesa un mensaje de Kafka: predice y guarda.
        
        Args:
            message: Mensaje de Kafka
        """
        start_time = time.time()
        
        try:
            # Extraer datos del mensaje
            record = message.value
            
            # Extraer caracter√≠sticas
            features = self.extract_features(record)
            
            # Realizar predicci√≥n
            predicted_score = self.predict(features)
            
            # Calcular tiempo de procesamiento
            processing_time = (time.time() - start_time) * 1000  # ms
            
            # Guardar en MySQL
            self.save_to_mysql(record, predicted_score, processing_time)
            
            # Log de resultado
            logger.info(
                f"‚úÖ Procesado #{record['record_id']}: "
                f"{record['country']} ({record['year']}) | "
                f"Real: {record['actual_score']:.2f} | "
                f"Predicho: {predicted_score:.2f} | "
                f"Error: {abs(record['actual_score'] - predicted_score):.2f} | "
                f"‚è±Ô∏è {processing_time:.2f}ms"
            )
            
        except Exception as e:
            logger.error(f"‚ùå Error al procesar mensaje: {e}")
    
    def consume_and_predict(self, timeout_ms: int = 1000) -> None:
        """
        Inicia el consumo de mensajes y procesamiento en tiempo real.
        
        Args:
            timeout_ms: Timeout para poll de mensajes
        """
        logger.info("üöÄ Iniciando consumo de mensajes...")
        logger.info("‚è∏Ô∏è  Presiona Ctrl+C para detener")
        
        try:
            messages_processed = 0
            
            for message in self.consumer:
                # Procesar mensaje
                self.process_message(message)
                messages_processed += 1
                
                # Log cada 10 mensajes
                if messages_processed % 10 == 0:
                    logger.info(f"üìä Total procesados: {messages_processed}")
                
        except KeyboardInterrupt:
            logger.warning("‚ö†Ô∏è Consumo interrumpido por usuario")
        except Exception as e:
            logger.error(f"‚ùå Error en consumo: {e}")
            raise
        finally:
            self.close()
    
    def close(self):
        """Cierra las conexiones de Kafka y MySQL"""
        try:
            self.consumer.close()
            logger.info("üîí Consumidor Kafka cerrado")
        except Exception as e:
            logger.error(f"‚ùå Error al cerrar consumidor: {e}")
        
        try:
            if self.mysql_conn.is_connected():
                self.mysql_conn.close()
                logger.info("üîí Conexi√≥n MySQL cerrada")
        except Exception as e:
            logger.error(f"‚ùå Error al cerrar MySQL: {e}")


# =============================================================================
# FUNCI√ìN PRINCIPAL
# =============================================================================

def main():
    """Funci√≥n principal para ejecutar el consumidor"""
    
    # Configuraci√≥n
    KAFKA_SERVER = 'localhost:9092'
    TOPIC = 'happiness-data'
    GROUP_ID = 'happiness-prediction-group'
    MODEL_PATH = 'modelo_regresion_lineal.pkl'
    
    # Configuraci√≥n MySQL
    MYSQL_CONFIG = {
        'host': 'localhost',
        'port': 3306,
        'database': 'happiness_db',
        'user': 'root',
        'password': 'root'  # ‚ö†Ô∏è Cambia esto por tu contrase√±a de MySQL
    }
    
    # Crear consumidor
    consumer = HappinessKafkaConsumer(
        bootstrap_servers=KAFKA_SERVER,
        topic=TOPIC,
        group_id=GROUP_ID,
        model_path=MODEL_PATH,
        mysql_config=MYSQL_CONFIG
    )
    
    # Iniciar consumo
    consumer.consume_and_predict()


if __name__ == "__main__":
    print("="*80)
    print("üöÄ KAFKA CONSUMER - World Happiness Report ML System")
    print("="*80)
    main()
